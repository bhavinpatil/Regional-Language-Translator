{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5a818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available.\n",
      "Using GPU: b'NVIDIA GeForce GTX 1650 Ti'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "# Check if a GPU is available\n",
    "if cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    \n",
    "    # Get the name of the GPU\n",
    "    gpu_name = cuda.get_current_device().name\n",
    "    print(f\"Using GPU: {gpu_name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"GPU is not available. Using CPU.\")\n",
    "\n",
    "# Your CUDA code here, if you want to run specific CUDA operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc0ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Input\n",
    "from numba import jit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9bee8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessed_data.csv', encoding='utf-8')\n",
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_sentences = df['Hindi']\n",
    "telugu_sentences = df['Telugu']\n",
    "hindi_train, hindi_val, telugu_train, telugu_val = train_test_split(hindi_sentences, telugu_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5072766",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "hindi_tokenizer.fit_on_texts(hindi_sentences)\n",
    "hindi_vocab_size = len(hindi_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc96f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "telugu_tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "telugu_tokenizer.fit_on_texts(telugu_sentences)\n",
    "telugu_vocab_size = len(telugu_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5a5438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(len(seq) for seq in hindi_train)\n",
    "hindi_train_sequences = pad_sequences(hindi_tokenizer.texts_to_sequences(hindi_train), maxlen=max_sequence_length, padding=\"post\")\n",
    "telugu_train_sequences = pad_sequences(telugu_tokenizer.texts_to_sequences(telugu_train), maxlen=max_sequence_length, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33cf07eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_evaluate_model(model, hindi_sequences, telugu_sequences, target_test_data):\n",
    "    evaluation = model.evaluate([hindi_sequences, telugu_sequences], target_test_data)\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "819ddb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpu_model(hindi_vocab_size, telugu_vocab_size, max_sequence_length):\n",
    "    encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    encoder_embedding = Embedding(hindi_vocab_size, 256, input_length=max_sequence_length)(encoder_inputs)\n",
    "    encoder_lstm = LSTM(256, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    decoder_embedding = Embedding(telugu_vocab_size, 256, input_length=max_sequence_length)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(telugu_vocab_size, activation=\"softmax\")\n",
    "    output = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d4dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_model = create_gpu_model(hindi_vocab_size, telugu_vocab_size, max_sequence_length)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d7c8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "target_train_data = tf.keras.utils.to_categorical(telugu_train_sequences, num_classes=telugu_vocab_size, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4319c61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10/10 [==============================] - 68s 6s/step - loss: 7.2085 - accuracy: 0.8752 - val_loss: 4.2181 - val_accuracy: 0.9725\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 62s 6s/step - loss: 1.8548 - accuracy: 0.9728 - val_loss: 0.3577 - val_accuracy: 0.9725\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 62s 6s/step - loss: 0.2877 - accuracy: 0.9728 - val_loss: 0.2603 - val_accuracy: 0.9725\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 63s 6s/step - loss: 0.2537 - accuracy: 0.9728 - val_loss: 0.2549 - val_accuracy: 0.9725\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 65s 7s/step - loss: 0.2472 - accuracy: 0.9728 - val_loss: 0.2543 - val_accuracy: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2298e2111d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_model.fit([hindi_train_sequences, telugu_train_sequences], target_train_data, epochs=epochs, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "808495ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 10s 1s/step - loss: 0.2505 - accuracy: 0.9731\n",
      "Test Loss: 0.25048258900642395\n",
      "Test Accuracy: 0.9730697870254517\n"
     ]
    }
   ],
   "source": [
    "hindi_test_sequences = pad_sequences(hindi_tokenizer.texts_to_sequences(hindi_val), maxlen=max_sequence_length, padding=\"post\")\n",
    "telugu_test_sequences = pad_sequences(telugu_tokenizer.texts_to_sequences(telugu_val), maxlen=max_sequence_length, padding=\"post\")\n",
    "\n",
    "target_test_data = tf.keras.utils.to_categorical(telugu_test_sequences, num_classes=telugu_vocab_size, dtype='float32')\n",
    "\n",
    "evaluation = gpu_evaluate_model(gpu_model, hindi_test_sequences, telugu_test_sequences, target_test_data)\n",
    "\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d7e4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "gpu_model.save('models/gpu_translation_model.keras')\n",
    "\n",
    "with open('tokenizers/gpu_hindi_tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(hindi_tokenizer, tokenizer_file)\n",
    "\n",
    "with open('tokenizers/gpu_telugu_tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(telugu_tokenizer, tokenizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bec249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
