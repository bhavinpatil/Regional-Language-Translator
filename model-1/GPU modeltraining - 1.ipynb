{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de5a818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "# Check if a GPU is available\n",
    "if cuda.is_available():\n",
    "    print(\"GPU is available.\")\n",
    "    \n",
    "    # Get the name of the GPU\n",
    "    gpu_name = cuda.get_current_device().name\n",
    "    print(f\"Using GPU: {gpu_name}\")\n",
    "    \n",
    "else:\n",
    "    print(\"GPU is not available. Using CPU.\")\n",
    "\n",
    "# Your CUDA code here, if you want to run specific CUDA operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc0ebe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 18:12:23.833737: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-06 18:12:23.874438: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-06 18:12:23.874472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-06 18:12:23.874499: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-06 18:12:23.881510: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-06 18:12:23.881956: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-06 18:12:24.955020: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Input\n",
    "from numba import jit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bee8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/preprocessed_data.csv', encoding='utf-8')\n",
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_sentences = df['Hindi']\n",
    "telugu_sentences = df['Telugu']\n",
    "hindi_train, hindi_val, telugu_train, telugu_val = train_test_split(hindi_sentences, telugu_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5072766",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "hindi_tokenizer.fit_on_texts(hindi_sentences)\n",
    "hindi_vocab_size = len(hindi_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc96f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "telugu_tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "telugu_tokenizer.fit_on_texts(telugu_sentences)\n",
    "telugu_vocab_size = len(telugu_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a5438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = max(len(seq) for seq in hindi_train)\n",
    "hindi_train_sequences = pad_sequences(hindi_tokenizer.texts_to_sequences(hindi_train), maxlen=max_sequence_length, padding=\"post\")\n",
    "telugu_train_sequences = pad_sequences(telugu_tokenizer.texts_to_sequences(telugu_train), maxlen=max_sequence_length, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33cf07eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_evaluate_model(model, hindi_sequences, telugu_sequences, target_test_data):\n",
    "    evaluation = model.evaluate([hindi_sequences, telugu_sequences], target_test_data)\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819ddb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gpu_model(hindi_vocab_size, telugu_vocab_size, max_sequence_length):\n",
    "    encoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    encoder_embedding = Embedding(hindi_vocab_size, 256, input_length=max_sequence_length)(encoder_inputs)\n",
    "    encoder_lstm = LSTM(256, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_inputs = Input(shape=(max_sequence_length,))\n",
    "    decoder_embedding = Embedding(telugu_vocab_size, 256, input_length=max_sequence_length)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(telugu_vocab_size, activation=\"softmax\")\n",
    "    output = decoder_dense(decoder_outputs)\n",
    "\n",
    "    model = Model([encoder_inputs, decoder_inputs], output)\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d4dee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 18:12:55.868390: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-06 18:12:55.869196: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "gpu_model = create_gpu_model(hindi_vocab_size, telugu_vocab_size, max_sequence_length)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d7c8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "target_train_data = tf.keras.utils.to_categorical(telugu_train_sequences, num_classes=telugu_vocab_size, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4319c61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-06 18:13:08.833714: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 5957529600 exceeds 10% of free system memory.\n",
      "2023-10-06 18:13:13.909869: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 595752960 exceeds 10% of free system memory.\n",
      "2023-10-06 18:13:13.911056: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 595752960 exceeds 10% of free system memory.\n",
      "2023-10-06 18:13:13.911361: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 595752960 exceeds 10% of free system memory.\n",
      "2023-10-06 18:13:13.912013: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 595752960 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 59s 6s/step - loss: 7.0471 - accuracy: 0.8757 - val_loss: 3.9726 - val_accuracy: 0.9725\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 53s 6s/step - loss: 1.6969 - accuracy: 0.9728 - val_loss: 0.3434 - val_accuracy: 0.9725\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 52s 5s/step - loss: 0.2813 - accuracy: 0.9728 - val_loss: 0.2596 - val_accuracy: 0.9725\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 56s 6s/step - loss: 0.2532 - accuracy: 0.9728 - val_loss: 0.2552 - val_accuracy: 0.9725\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 55s 6s/step - loss: 0.2481 - accuracy: 0.9728 - val_loss: 0.2546 - val_accuracy: 0.9725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f298c0dec90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_model.fit([hindi_train_sequences, telugu_train_sequences], target_train_data, epochs=epochs, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "808495ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 6s 788ms/step - loss: 0.2516 - accuracy: 0.9731\n",
      "Test Loss: 0.25158432126045227\n",
      "Test Accuracy: 0.9730697870254517\n"
     ]
    }
   ],
   "source": [
    "hindi_test_sequences = pad_sequences(hindi_tokenizer.texts_to_sequences(hindi_val), maxlen=max_sequence_length, padding=\"post\")\n",
    "telugu_test_sequences = pad_sequences(telugu_tokenizer.texts_to_sequences(telugu_val), maxlen=max_sequence_length, padding=\"post\")\n",
    "\n",
    "target_test_data = tf.keras.utils.to_categorical(telugu_test_sequences, num_classes=telugu_vocab_size, dtype='float32')\n",
    "\n",
    "evaluation = gpu_evaluate_model(gpu_model, hindi_test_sequences, telugu_test_sequences, target_test_data)\n",
    "\n",
    "print(\"Test Loss:\", evaluation[0])\n",
    "print(\"Test Accuracy:\", evaluation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d7e4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "gpu_model.save('models/gpu_translation_model.keras')\n",
    "\n",
    "with open('tokenizers/gpu_hindi_tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(hindi_tokenizer, tokenizer_file)\n",
    "\n",
    "with open('tokenizers/gpu_telugu_tokenizer.pkl', 'wb') as tokenizer_file:\n",
    "    pickle.dump(telugu_tokenizer, tokenizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bec249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
