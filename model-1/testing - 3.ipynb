{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c25d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence: [[ 16 272  32  33 994   4   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "1/1 [==============================] - 1s 616ms/step\n",
      "Predicted Sequence: [[[1.3475874e-01 3.1189658e-05 1.8417988e-02 ... 1.9301640e-05\n",
      "   2.5325788e-05 2.6087635e-05]\n",
      "  [1.3328493e-01 3.2373737e-05 1.7667376e-02 ... 1.9994148e-05\n",
      "   2.5947542e-05 2.6897907e-05]\n",
      "  [1.3968104e-01 3.2151202e-05 1.6697248e-02 ... 2.0420883e-05\n",
      "   2.5645031e-05 2.6802583e-05]\n",
      "  ...\n",
      "  [9.9648845e-01 8.1137365e-08 1.8086119e-05 ... 5.7395802e-08\n",
      "   5.8666085e-08 5.6843447e-08]\n",
      "  [9.9648845e-01 8.1137365e-08 1.8086119e-05 ... 5.7395802e-08\n",
      "   5.8666085e-08 5.6843447e-08]\n",
      "  [9.9648845e-01 8.1137365e-08 1.8086119e-05 ... 5.7395802e-08\n",
      "   5.8666085e-08 5.6843447e-08]]]\n",
      "Hindi:  यह विचार बहुत ही सरल है\n",
      "Telugu:  \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('models/translation_model1.keras')\n",
    "\n",
    "# Load the Hindi tokenizer\n",
    "with open('tokenizers/hindi_tokenizer1.pkl', 'rb') as tokenizer_file:\n",
    "    hindi_tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# Load the Telugu tokenizer\n",
    "with open('tokenizers/telugu_tokenizer1.pkl', 'rb') as tokenizer_file:\n",
    "    telugu_tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# Function to translate a Hindi sentence to Telugu\n",
    "def translate_to_telugu(input_text):\n",
    "    # Tokenize and pad the input Hindi sentence\n",
    "    input_sequence = hindi_tokenizer.texts_to_sequences([input_text])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=90, padding=\"post\")\n",
    "\n",
    "    # Print the input sequence for debugging\n",
    "    print(\"Input Sequence:\", input_sequence)\n",
    "\n",
    "    # Use the model to predict the Telugu translation\n",
    "    predicted_sequence = model.predict([input_sequence, input_sequence])\n",
    "\n",
    "    # Print the predicted sequence for debugging\n",
    "    print(\"Predicted Sequence:\", predicted_sequence)\n",
    "\n",
    "    # Convert the predicted sequence to Telugu text\n",
    "    predicted_text = []\n",
    "    for token_index in predicted_sequence[0]:\n",
    "        predicted_word = telugu_tokenizer.index_word.get(np.argmax(token_index))\n",
    "        if predicted_word == \"<OOV>\":\n",
    "            continue\n",
    "        if predicted_word == \"<end>\":\n",
    "            break\n",
    "        if predicted_word:\n",
    "            predicted_text.append(predicted_word)\n",
    "\n",
    "    # Join the Telugu words to form the translated sentence\n",
    "    translated_sentence = \" \".join(predicted_text)\n",
    "\n",
    "    return translated_sentence\n",
    "\n",
    "# Example usage\n",
    "input_text = \"यह विचार बहुत ही सरल है\"\n",
    "translated_sentence = translate_to_telugu(input_text)\n",
    "print(\"Hindi: \", input_text)\n",
    "print(\"Telugu: \", translated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c265969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence: [[ 16 272  32  33 994   4   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "1/1 [==============================] - 1s 716ms/step\n",
      "Predicted Sequence: [[[1.3475874e-01 3.1189658e-05 1.8417988e-02 ... 1.9301640e-05\n",
      "   2.5325788e-05 2.6087635e-05]\n",
      "  [1.3328493e-01 3.2373737e-05 1.7667376e-02 ... 1.9994148e-05\n",
      "   2.5947542e-05 2.6897907e-05]\n",
      "  [1.3968104e-01 3.2151202e-05 1.6697248e-02 ... 2.0420883e-05\n",
      "   2.5645031e-05 2.6802583e-05]\n",
      "  ...\n",
      "  [9.9648845e-01 8.1137365e-08 1.8086119e-05 ... 5.7395802e-08\n",
      "   5.8666085e-08 5.6843447e-08]\n",
      "  [9.9648845e-01 8.1137365e-08 1.8086119e-05 ... 5.7395802e-08\n",
      "   5.8666085e-08 5.6843447e-08]\n",
      "  [9.9648845e-01 8.1137365e-08 1.8086119e-05 ... 5.7395802e-08\n",
      "   5.8666085e-08 5.6843447e-08]]]\n",
      "Hindi:  यह विचार बहुत ही सरल है\n",
      "Telugu:  \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('models/translation_model1.keras')\n",
    "\n",
    "# Load the Hindi tokenizer\n",
    "with open('tokenizers/hindi_tokenizer1.pkl', 'rb') as tokenizer_file:\n",
    "    hindi_tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# Load the Telugu tokenizer\n",
    "with open('tokenizers/telugu_tokenizer1.pkl', 'rb') as tokenizer_file:\n",
    "    telugu_tokenizer = pickle.load(tokenizer_file)\n",
    "\n",
    "# Function to translate a Hindi sentence to Telugu\n",
    "def translate_to_telugu(input_text):\n",
    "    # Tokenize and pad the input Hindi sentence\n",
    "    input_sequence = hindi_tokenizer.texts_to_sequences([input_text])\n",
    "    input_sequence = pad_sequences(input_sequence, maxlen=90, padding=\"post\")\n",
    "\n",
    "    # Print the input sequence for debugging\n",
    "    print(\"Input Sequence:\", input_sequence)\n",
    "\n",
    "    # Use the model to predict the Telugu translation\n",
    "    predicted_sequence = model.predict([input_sequence, input_sequence])\n",
    "\n",
    "    # Print the predicted sequence for debugging\n",
    "    print(\"Predicted Sequence:\", predicted_sequence)\n",
    "\n",
    "    # Convert the predicted sequence to Telugu text\n",
    "    predicted_text = []\n",
    "    for token_index in predicted_sequence[0]:\n",
    "        predicted_word = telugu_tokenizer.index_word.get(np.argmax(token_index))\n",
    "        if predicted_word == \"<OOV>\":\n",
    "            continue\n",
    "        if predicted_word == \"<end>\":\n",
    "            break\n",
    "        if predicted_word:\n",
    "            predicted_text.append(predicted_word)\n",
    "            # Print each translated word\n",
    "            print(\"Translated Word:\", predicted_word)\n",
    "\n",
    "    # Join the Telugu words to form the translated sentence\n",
    "    translated_sentence = \" \".join(predicted_text)\n",
    "\n",
    "    return translated_sentence\n",
    "\n",
    "# Example usage\n",
    "input_text = \"यह विचार बहुत ही सरल है\"\n",
    "translated_sentence = translate_to_telugu(input_text)\n",
    "print(\"Hindi: \", input_text)\n",
    "print(\"Telugu: \", translated_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
